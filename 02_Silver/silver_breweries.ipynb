{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "941c08ed-6d1f-4bfa-bb7d-e3f8c04a48c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Silver Layer\n",
    "Silver Layer: Transform the data to a columnar storage format such as parquet or delta, and partition it by brewery location. Please explain any other transformations you perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3525410b-af2b-4155-8075-13012dbe8919",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Libs"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.utils import AnalysisException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88741de5-baaa-44c6-b6ba-68d7067a34e5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read the Last Partition and Read Table"
    }
   },
   "outputs": [],
   "source": [
    "partitions = spark.sql(\"SHOW PARTITIONS ab_inbev_lake.bronze.breweries_api_data\")\n",
    "last_partition = partitions.agg(max(col(\"execution_date\")).alias(\"last_partition\")).collect()[0][\"last_partition\"]\n",
    "df_bronze = spark.read.table(\"ab_inbev_lake.bronze.breweries_api_data\").filter(col(\"execution_date\") == last_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b15869d-78e1-46a1-8d6f-57f68c3328a2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformations"
    }
   },
   "outputs": [],
   "source": [
    "df_bronze = (\n",
    "    df_bronze\n",
    "    .withColumnRenamed('id', 'cd_id')\\\n",
    "    .withColumnRenamed('name', 'nm_brewery')\\\n",
    "    .withColumnRenamed('brewery_type', 'ds_brewery_type')\\\n",
    "    .withColumnRenamed('address_1', 'nm_address_1')\\\n",
    "    .withColumnRenamed('address_2', 'nm_address_2')\\\n",
    "    .withColumnRenamed('address_3', 'nm_address_3')\\\n",
    "    .withColumnRenamed('country', 'nm_country')\\\n",
    "    .withColumnRenamed('state', 'nm_state')\\\n",
    "    .withColumnRenamed('city', 'nm_city')\\\n",
    "    .withColumnRenamed('postal_code', 'cd_postal_code')\\\n",
    "    .withColumnRenamed('longitude', 'nr_longitude')\\\n",
    "    .withColumnRenamed('latitude', 'nr_latitude')\\\n",
    "    .withColumnRenamed('phone', 'ds_phone')\\\n",
    "    .withColumnRenamed('website_url', 'url_website')\\\n",
    "    .withColumnRenamed('state_province', 'nm_state_province')\\\n",
    "    .withColumnRenamed('execution_date', 'dt_insert')\\\n",
    "    .withColumnRenamed('street', 'nm_street')\\\n",
    "    .withColumnRenamed('url_website', 'ds_website')\\\n",
    ")\n",
    "\n",
    "df_bronze = (\n",
    "    df_bronze\n",
    "    .withColumn(\"nr_longitude\", col(\"nr_longitude\").cast(\"double\"))\n",
    "    .withColumn(\"nr_latitude\", col(\"nr_latitude\").cast(\"double\"))\n",
    "    .withColumn(\"ds_status\", when(col(\"ds_brewery_type\") == 'closed', 'inactive').otherwise('active'))\n",
    "    .withColumn(\"dt_update\", col(\"dt_insert\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2372eaf0-03d6-4d27-ba45-f57e593fee78",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define Schema and Quality"
    }
   },
   "outputs": [],
   "source": [
    "expected_schema = StructType([\n",
    "    StructField(\"cd_id\", StringType(), False),\n",
    "    StructField(\"nm_brewery\", StringType(), True),\n",
    "    StructField(\"ds_brewery_type\", StringType(), True),\n",
    "    StructField(\"nm_address_1\", StringType(), True),\n",
    "    StructField(\"nm_address_2\", StringType(), True),\n",
    "    StructField(\"nm_address_3\", StringType(), True),\n",
    "    StructField(\"nm_country\", StringType(), True),\n",
    "    StructField(\"nm_state\", StringType(), True),\n",
    "    StructField(\"nm_city\", StringType(), True),\n",
    "    StructField(\"cd_postal_code\", StringType(), True),\n",
    "    StructField(\"nr_longitude\", DoubleType(), True),\n",
    "    StructField(\"nr_latitude\", DoubleType(), True),\n",
    "    StructField(\"ds_phone\", StringType(), True),\n",
    "    StructField(\"ds_website\", StringType(), True),\n",
    "    StructField(\"nm_state_province\", StringType(), True),\n",
    "    StructField(\"dt_insert\", TimestampType(), True),\n",
    "    StructField(\"nm_street\", StringType(), True),\n",
    "    StructField(\"ds_status\", StringType(), True),\n",
    "    StructField(\"dt_update\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "def validate_schema(df: DataFrame, expected_schema: StructType) -> bool:\n",
    "    \"\"\"\n",
    "    Verifica se o schema do DataFrame corresponde exatamente ao schema esperado.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        DataFrame do Spark a ser validado.\n",
    "    expected_schema : StructType\n",
    "        Schema esperado para validação.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True se o schema do DataFrame for igual ao esperado, False caso contrário.\n",
    "    \"\"\"\n",
    "    df_fields = [(f.name, f.dataType) for f in df.schema.fields]\n",
    "    expected_fields = [(f.name, f.dataType) for f in expected_schema.fields]\n",
    "    return df_fields == expected_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8b1f894-769d-459b-84ec-87506220caed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function to Compare Schema Tables"
    }
   },
   "outputs": [],
   "source": [
    "def get_table_schema(table_name: str) -> StructType:\n",
    "    \"\"\"\n",
    "    Returns the schema of the specified table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name : str\n",
    "        Name of the table to retrieve the schema from.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    StructType or None\n",
    "        The schema of the table if it exists, otherwise None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return spark.table(table_name).schema\n",
    "    except AnalysisException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1449654b-5063-437c-8f80-4b6d66541f18",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Quality and Write Table"
    }
   },
   "outputs": [],
   "source": [
    "df_bronze_casted = df_bronze.select(\n",
    "    [col(field.name).cast(field.dataType) for field in expected_schema.fields]\n",
    ")\n",
    "\n",
    "if validate_schema(df_bronze_casted, expected_schema):\n",
    "\n",
    "    silver_table = \"ab_inbev_lake.silver.breweries\"\n",
    "\n",
    "    table_schema = get_table_schema(silver_table)\n",
    "\n",
    "    if table_schema is None or table_schema != expected_schema:\n",
    "        (\n",
    "            df_bronze_casted\n",
    "            .write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .partitionBy(\"nm_country\")\n",
    "            .option(\"overwriteSchema\", \"true\")\n",
    "            .option(\"mergeSchema\", \"true\")\n",
    "            .saveAsTable(silver_table)\n",
    "        )\n",
    "\n",
    "    compare_cols = [\n",
    "        c for c in df_bronze_casted.columns if c not in [\"cd_id\", \"dt_insert\", \"dt_update\"]\n",
    "    ]\n",
    "    change_condition = \" OR \".join([f\"source.{c} <> target.{c}\" for c in compare_cols])\n",
    "\n",
    "    delta_silver = DeltaTable.forName(spark, silver_table)\n",
    "    (\n",
    "        delta_silver.alias(\"target\")\n",
    "        .merge(\n",
    "            df_bronze_casted.alias(\"source\"),\n",
    "            \"target.cd_id = source.cd_id\"\n",
    "        )\n",
    "        .whenMatchedUpdate(\n",
    "            condition=change_condition,\n",
    "            set={\n",
    "                **{col: f\"source.{col}\" for col in compare_cols},\n",
    "                \"dt_update\": \"source.dt_update\"\n",
    "            }\n",
    "        )\n",
    "        .whenNotMatchedInsert(\n",
    "            values={col: f\"source.{col}\" for col in df_bronze_casted.columns}\n",
    "        )\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    spark.sql(f\"OPTIMIZE {silver_table}\")\n",
    "\n",
    "    spark.sql(f\"OPTIMIZE {silver_table} ZORDER BY (nm_city)\")\n",
    "else:\n",
    "    raise ValueError(\"Schema mismatch: DataFrame does not match the expected schema.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8308217810585670,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_breweries",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
